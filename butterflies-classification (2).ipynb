{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":10809628,"sourceType":"datasetVersion","datasetId":6710109},{"sourceId":10843145,"sourceType":"datasetVersion","datasetId":6734009}],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Phan Khánh Toàn - HE170983","metadata":{}},{"cell_type":"code","source":"import os\nimport copy\nimport pandas as pd\nfrom PIL import Image\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader, random_split\nfrom torchvision import transforms, models","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-24T17:38:55.123559Z","iopub.execute_input":"2025-02-24T17:38:55.123793Z","iopub.status.idle":"2025-02-24T17:39:01.791992Z","shell.execute_reply.started":"2025-02-24T17:38:55.123773Z","shell.execute_reply":"2025-02-24T17:39:01.791339Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"class ButterflyDataset(Dataset):\n    def __init__(self, csv_file, root_dir, transform=None, label_encoder=None):\n        \"\"\"\n        csv_file: đường dẫn file CSV (Training_set.csv)\n        root_dir: thư mục chứa ảnh train (butterfl/train/train)\n        transform: phép biến đổi (transforms) cho ảnh\n        label_encoder: dict ánh xạ label_string -> label_index\n        \"\"\"\n        self.df = pd.read_csv(csv_file)\n        self.root_dir = root_dir\n        self.transform = transform\n        self.label_encoder = label_encoder\n        \n        # Nếu chưa có label_encoder, ta sẽ tự tạo (áp dụng cho train dataset)\n        if self.label_encoder is None:\n            unique_labels = self.df['label'].unique().tolist()\n            self.label_encoder = {lab: i for i, lab in enumerate(unique_labels)}\n\n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, idx):\n        row = self.df.iloc[idx]\n        img_name = row['filename']\n        label_str = row['label']\n        \n        # Đường dẫn đầy đủ tới ảnh\n        img_path = os.path.join(self.root_dir, img_name)\n        \n        # Mở ảnh\n        image = Image.open(img_path).convert(\"RGB\")\n        \n        # Gán nhãn (dạng index)\n        label = self.label_encoder[label_str]\n        \n        # Áp dụng transform\n        if self.transform:\n            image = self.transform(image)\n        \n        return image, label\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-24T17:39:05.953829Z","iopub.execute_input":"2025-02-24T17:39:05.954152Z","iopub.status.idle":"2025-02-24T17:39:05.960758Z","shell.execute_reply.started":"2025-02-24T17:39:05.954130Z","shell.execute_reply":"2025-02-24T17:39:05.959844Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"csv_path = \"/kaggle/input/new-dataset-butterflies/Training_set.csv\"\ntrain_img_dir = \"/kaggle/input/new-dataset-butterflies/train\"\n\n# Bước 1: Tạo dataset tạm để lấy label_encoder\ntemp_dataset = ButterflyDataset(csv_file=csv_path, root_dir=train_img_dir)\n\n# Lấy label_encoder ra, để dùng nhất quán cho train/val\nlabel_encoder = temp_dataset.label_encoder\nnum_classes = len(label_encoder)\nprint(\"Số lớp (num_classes):\", num_classes)\n\n# Bước 2: Tạo dataset chính thức (có label_encoder)\n# Ta dùng chung dataset, sau đó split ra train_dataset và val_dataset\nfull_dataset = ButterflyDataset(csv_file=csv_path, \n                               root_dir=train_img_dir,\n                               transform=None, \n                               label_encoder=label_encoder)\n\n# -----------------------------------------\n#  CHIA TRAIN/VAL THEO TỶ LỆ (VD: 80% / 20%)\n# -----------------------------------------\ntrain_size = int(0.8 * len(full_dataset))\nval_size = len(full_dataset) - train_size\ntrain_dataset, val_dataset = random_split(full_dataset, [train_size, val_size])\n\nprint(f\"Tổng số mẫu: {len(full_dataset)}\")\nprint(f\"Train size: {len(train_dataset)} | Val size: {len(val_dataset)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-24T17:39:08.707157Z","iopub.execute_input":"2025-02-24T17:39:08.707466Z","iopub.status.idle":"2025-02-24T17:39:08.765082Z","shell.execute_reply.started":"2025-02-24T17:39:08.707441Z","shell.execute_reply":"2025-02-24T17:39:08.764414Z"}},"outputs":[{"name":"stdout","text":"Số lớp (num_classes): 75\nTổng số mẫu: 6499\nTrain size: 5199 | Val size: 1300\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"train_transform = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.RandomHorizontalFlip(p=0.5),\n    transforms.RandomRotation(degrees=15),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n                         std =[0.229, 0.224, 0.225])\n])\n\nval_transform = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n                         std =[0.229, 0.224, 0.225])\n])\n\n# Gán transform tương ứng\ntrain_dataset.dataset.transform = train_transform  # dataset gốc nằm trong .dataset\nval_dataset.dataset.transform   = val_transform\n\n# -----------------------------------------\n#  DATALOADER\n# -----------------------------------------\ntrain_loader = DataLoader(train_dataset, batch_size=32, shuffle=True,  num_workers=2)\nval_loader   = DataLoader(val_dataset,   batch_size=32, shuffle=False, num_workers=2)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-24T17:39:17.409632Z","iopub.execute_input":"2025-02-24T17:39:17.409950Z","iopub.status.idle":"2025-02-24T17:39:17.415950Z","shell.execute_reply.started":"2025-02-24T17:39:17.409925Z","shell.execute_reply":"2025-02-24T17:39:17.414872Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(\"Device:\", device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-24T17:39:35.654617Z","iopub.execute_input":"2025-02-24T17:39:35.654929Z","iopub.status.idle":"2025-02-24T17:39:35.659605Z","shell.execute_reply.started":"2025-02-24T17:39:35.654870Z","shell.execute_reply":"2025-02-24T17:39:35.658962Z"}},"outputs":[{"name":"stdout","text":"Device: cuda\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"# -----------------------------------------\n#  KHỞI TẠO RESNET18 PRETRAINED\n# -----------------------------------------\nmodel = models.resnet18(pretrained=True)\n# Số đầu vào của FC cuối\nin_features = model.fc.in_features\n# Thay FC cuối bằng lớp Linear có num_classes đầu ra\nmodel.fc = nn.Linear(in_features, num_classes)\n\nmodel = model.to(device)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-24T17:39:53.815152Z","iopub.execute_input":"2025-02-24T17:39:53.815469Z","iopub.status.idle":"2025-02-24T17:39:54.608248Z","shell.execute_reply.started":"2025-02-24T17:39:53.815443Z","shell.execute_reply":"2025-02-24T17:39:54.607568Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\nDownloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n100%|██████████| 44.7M/44.7M [00:00<00:00, 175MB/s]\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"# Loss và Optimizer\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr=1e-4)\n\n# -----------------------------------------\n#  TRAIN VỚI EARLY STOPPING\n# -----------------------------------------\nbest_acc = 0.0\nbest_model_wts = copy.deepcopy(model.state_dict())\n\npatience = 5\ntrigger_times = 0\n\nnum_epochs = 50\nfor epoch in range(num_epochs):\n    print(f\"\\nEpoch {epoch+1}/{num_epochs}\")\n    print(\"-\" * 30)\n\n    for phase in ['train', 'val']:\n        if phase == 'train':\n            model.train()\n            dataloader = train_loader\n        else:\n            model.eval()\n            dataloader = val_loader\n\n        running_loss = 0.0\n        running_corrects = 0\n\n        for inputs, labels in dataloader:\n            inputs, labels = inputs.to(device), labels.to(device)\n            optimizer.zero_grad()\n\n            with torch.set_grad_enabled(phase == 'train'):\n                outputs = model(inputs)\n                loss = criterion(outputs, labels)\n                _, preds = torch.max(outputs, 1)\n\n                if phase == 'train':\n                    loss.backward()\n                    optimizer.step()\n\n            running_loss += loss.item() * inputs.size(0)\n            running_corrects += torch.sum(preds == labels.data)\n\n        epoch_loss = running_loss / len(dataloader.dataset)\n        epoch_acc  = running_corrects.double() / len(dataloader.dataset)\n\n        print(f\"{phase} Loss: {epoch_loss:.4f} | Acc: {epoch_acc:.4f}\")\n\n        # Check early stopping trên val\n        if phase == 'val':\n            if epoch_acc > best_acc:\n                best_acc = epoch_acc\n                best_model_wts = copy.deepcopy(model.state_dict())\n                trigger_times = 0\n            else:\n                trigger_times += 1\n                print(f\"-> EarlyStopping counter: {trigger_times} / {patience}\")\n                if trigger_times >= patience:\n                    print(\"-> Early stopping!\")\n                    model.load_state_dict(best_model_wts)\n                    break\n\n    if trigger_times >= patience:\n        break\n\nprint(f\"\\nHoàn tất training. Best val Acc: {best_acc:.4f}\")\nmodel.load_state_dict(best_model_wts)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-24T17:40:00.415489Z","iopub.execute_input":"2025-02-24T17:40:00.415777Z","iopub.status.idle":"2025-02-24T17:44:15.573591Z","shell.execute_reply.started":"2025-02-24T17:40:00.415757Z","shell.execute_reply":"2025-02-24T17:44:15.572434Z"}},"outputs":[{"name":"stdout","text":"\nEpoch 1/50\n------------------------------\ntrain Loss: 1.9847 | Acc: 0.6284\nval Loss: 0.7170 | Acc: 0.8769\n\nEpoch 2/50\n------------------------------\ntrain Loss: 0.4301 | Acc: 0.9331\nval Loss: 0.4046 | Acc: 0.9223\n\nEpoch 3/50\n------------------------------\ntrain Loss: 0.1623 | Acc: 0.9823\nval Loss: 0.3730 | Acc: 0.9115\n-> EarlyStopping counter: 1 / 5\n\nEpoch 4/50\n------------------------------\ntrain Loss: 0.0730 | Acc: 0.9931\nval Loss: 0.3202 | Acc: 0.9277\n\nEpoch 5/50\n------------------------------\ntrain Loss: 0.0314 | Acc: 0.9990\nval Loss: 0.3039 | Acc: 0.9285\n\nEpoch 6/50\n------------------------------\ntrain Loss: 0.0195 | Acc: 0.9996\nval Loss: 0.3070 | Acc: 0.9277\n-> EarlyStopping counter: 1 / 5\n\nEpoch 7/50\n------------------------------\ntrain Loss: 0.0165 | Acc: 0.9990\nval Loss: 0.2930 | Acc: 0.9338\n\nEpoch 8/50\n------------------------------\ntrain Loss: 0.0117 | Acc: 0.9996\nval Loss: 0.2808 | Acc: 0.9362\n\nEpoch 9/50\n------------------------------\ntrain Loss: 0.0086 | Acc: 0.9996\nval Loss: 0.2868 | Acc: 0.9315\n-> EarlyStopping counter: 1 / 5\n\nEpoch 10/50\n------------------------------\ntrain Loss: 0.0065 | Acc: 0.9998\nval Loss: 0.2931 | Acc: 0.9362\n-> EarlyStopping counter: 2 / 5\n\nEpoch 11/50\n------------------------------\ntrain Loss: 0.0053 | Acc: 0.9996\nval Loss: 0.2853 | Acc: 0.9331\n-> EarlyStopping counter: 3 / 5\n\nEpoch 12/50\n------------------------------\ntrain Loss: 0.0046 | Acc: 0.9998\nval Loss: 0.2870 | Acc: 0.9323\n-> EarlyStopping counter: 4 / 5\n\nEpoch 13/50\n------------------------------\ntrain Loss: 0.0041 | Acc: 0.9998\nval Loss: 0.2870 | Acc: 0.9369\n\nEpoch 14/50\n------------------------------\ntrain Loss: 0.0054 | Acc: 0.9996\nval Loss: 0.2984 | Acc: 0.9354\n-> EarlyStopping counter: 1 / 5\n\nEpoch 15/50\n------------------------------\ntrain Loss: 0.0037 | Acc: 1.0000\nval Loss: 0.2890 | Acc: 0.9323\n-> EarlyStopping counter: 2 / 5\n\nEpoch 16/50\n------------------------------\ntrain Loss: 0.0024 | Acc: 1.0000\nval Loss: 0.2956 | Acc: 0.9277\n-> EarlyStopping counter: 3 / 5\n\nEpoch 17/50\n------------------------------\ntrain Loss: 0.0021 | Acc: 1.0000\nval Loss: 0.2904 | Acc: 0.9300\n-> EarlyStopping counter: 4 / 5\n\nEpoch 18/50\n------------------------------\ntrain Loss: 0.0016 | Acc: 1.0000\nval Loss: 0.2902 | Acc: 0.9323\n-> EarlyStopping counter: 5 / 5\n-> Early stopping!\n\nHoàn tất training. Best val Acc: 0.9369\n","output_type":"stream"},{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"<All keys matched successfully>"},"metadata":{}}],"execution_count":9},{"cell_type":"code","source":"#  LƯU MODEL (NẾU MUỐN)\n# -----------------------------------------\ntorch.save(model.state_dict(), \"best_resnet18.pth\")\nprint(\"Model đã lưu vào best_resnet18.pth\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-24T17:44:32.754290Z","iopub.execute_input":"2025-02-24T17:44:32.754625Z","iopub.status.idle":"2025-02-24T17:44:32.833353Z","shell.execute_reply.started":"2025-02-24T17:44:32.754596Z","shell.execute_reply":"2025-02-24T17:44:32.832438Z"}},"outputs":[{"name":"stdout","text":"Model đã lưu vào best_resnet18.pth\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"#  PREDICT TRÊN TẬP TEST & TẠO SUBMISSION\n# -----------------------------------------\n# 1) Tạo Dataset cho test (không có nhãn)\n#    Ta chỉ cần cột 'filename' và đường dẫn ảnh.\nclass ButterflyTestDataset(Dataset):\n    def __init__(self, test_dir, transform=None):\n        \"\"\"\n        test_dir: thư mục 'butterfl/test/test' chứa các ảnh test\n        transform: phép biến đổi ảnh\n        \"\"\"\n        self.test_dir = test_dir\n        self.filenames = os.listdir(test_dir)  # danh sách file ảnh\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.filenames)\n\n    def __getitem__(self, idx):\n        img_name = self.filenames[idx]\n        img_path = os.path.join(self.test_dir, img_name)\n\n        image = Image.open(img_path).convert(\"RGB\")\n        if self.transform:\n            image = self.transform(image)\n\n        return image, img_name  # trả về cả filename để ghi kết quả\n\ntest_dir = \"/kaggle/input/butterfl/test/test\"\ntest_transform = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(),\n    transforms.Normalize([0.485, 0.456, 0.406],\n                         [0.229, 0.224, 0.225])\n])\n\ntest_dataset = ButterflyTestDataset(test_dir=test_dir, transform=test_transform)\ntest_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=2)\n\n# 2) Dự đoán\nmodel.eval()\npredictions = []\nfilenames_list = []\n\n# Đảo ngược label_encoder: index -> label_str\ninv_label_encoder = {v: k for k, v in label_encoder.items()}\n\nwith torch.no_grad():\n    for inputs, fnames in test_loader:\n        inputs = inputs.to(device)\n        outputs = model(inputs)\n        _, preds = torch.max(outputs, 1)\n\n        # Chuyển index -> tên class\n        for i in range(len(preds)):\n            pred_label_idx = preds[i].item()\n            pred_label_str = inv_label_encoder[pred_label_idx]\n\n            filename = fnames[i]\n            filenames_list.append(filename)\n            predictions.append(pred_label_str)\n\n# 3) Tạo file submission\nsubmission_df = pd.DataFrame({\n    'ID': filenames_list,\n    'label': predictions\n})\n\nsubmission_df.to_csv(\"submission.csv\", index=False)\nprint(\"Đã tạo file submission.csv\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-24T17:45:06.353350Z","iopub.execute_input":"2025-02-24T17:45:06.353658Z","iopub.status.idle":"2025-02-24T17:45:11.849049Z","shell.execute_reply.started":"2025-02-24T17:45:06.353637Z","shell.execute_reply":"2025-02-24T17:45:11.848000Z"}},"outputs":[{"name":"stdout","text":"Đã tạo file submission.csv\n","output_type":"stream"}],"execution_count":11}]}